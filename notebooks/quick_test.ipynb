{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7878d7dd",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35d49f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import numpy as np\n",
    "from IPython.display import Video, Image as IPImage\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, str(Path.cwd().parent / \"src\"))\n",
    "\n",
    "print(\"Setup complete!\")\n",
    "print(f\"Working directory: {Path.cwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e94c3f",
   "metadata": {},
   "source": [
    "## Step 1: Data Preprocessing (Dry-Run)\n",
    "\n",
    "Process just the first video from each split for quick testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394f0a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Run data pipeline in dry-run mode (processes only first video per split)\n",
    "python ../src/data_pipeline.py --dry-run --fps 1 --min-area 100\n",
    "\n",
    "# Check output\n",
    "echo \"\"\n",
    "echo \"Dataset created at: datasets/merged/\"\n",
    "echo \"Config created at: configs/dataset_video.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e029561f",
   "metadata": {},
   "source": [
    "## Step 2: Inspect Dataset\n",
    "\n",
    "Let's look at a sample image and its YOLO label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cca06a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_pipeline import mask_to_yolo_boxes\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Find a sample image\n",
    "merged_dir = Path(\"../datasets/merged\")\n",
    "train_images = list((merged_dir / \"images\" / \"train\").glob(\"*.jpg\"))\n",
    "\n",
    "if train_images:\n",
    "    sample_img = train_images[0]\n",
    "    sample_label = merged_dir / \"labels\" / \"train\" / f\"{sample_img.stem}.txt\"\n",
    "    \n",
    "    # Read image\n",
    "    img = cv2.imread(str(sample_img))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    h, w = img.shape[:2]\n",
    "    \n",
    "    # Read labels\n",
    "    if sample_label.exists():\n",
    "        with open(sample_label, 'r') as f:\n",
    "            labels = [line.strip().split() for line in f.readlines()]\n",
    "        \n",
    "        # Draw boxes\n",
    "        for label in labels:\n",
    "            cls, x_center, y_center, width, height = map(float, label)\n",
    "            \n",
    "            # Convert to pixel coordinates\n",
    "            x1 = int((x_center - width/2) * w)\n",
    "            y1 = int((y_center - height/2) * h)\n",
    "            x2 = int((x_center + width/2) * w)\n",
    "            y2 = int((y_center + height/2) * h)\n",
    "            \n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    \n",
    "    # Display\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Sample: {sample_img.name}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Image: {sample_img.name}\")\n",
    "    print(f\"Labels: {len(labels) if sample_label.exists() else 0} boxes\")\n",
    "else:\n",
    "    print(\"No training images found. Run data pipeline first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b77e3ee",
   "metadata": {},
   "source": [
    "## Step 3: Train Model (Quick Test)\n",
    "\n",
    "Train for just 5 epochs as a quick test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf08e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Quick training run (5 epochs)\n",
    "python ../src/train_yolo.py --model yolov8n.pt --epochs 5 --batch 8 --imgsz 320\n",
    "\n",
    "echo \"\"\n",
    "echo \"Training complete!\"\n",
    "echo \"Weights saved to: runs/detect/video_merged/weights/best.pt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9c189f",
   "metadata": {},
   "source": [
    "## Step 4: Run Demo Inference\n",
    "\n",
    "Run inference on a test video and generate outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa4a7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we have a test video\n",
    "test_videos_dir = Path(\"../datasets/Video_dataset/test/rgb\")\n",
    "sample_videos = list(test_videos_dir.glob(\"*.mp4\")) if test_videos_dir.exists() else []\n",
    "\n",
    "if sample_videos:\n",
    "    test_video = sample_videos[0]\n",
    "    print(f\"Found test video: {test_video.name}\")\n",
    "else:\n",
    "    # Use any available video\n",
    "    print(\"No test video found. Place a video at datasets/samples/my_road_video.mp4\")\n",
    "    test_video = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f1ec29",
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_video:\n",
    "    !python ../src/run_demo.py \\\n",
    "        --weights ../runs/detect/video_merged/weights/best.pt \\\n",
    "        --video {test_video} \\\n",
    "        --output ../outputs \\\n",
    "        --conf 0.25\n",
    "    \n",
    "    print(\"\\nDemo inference complete!\")\n",
    "    print(\"Check outputs/ directory for results\")\n",
    "else:\n",
    "    print(\"Skipping demo - no test video available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09887b20",
   "metadata": {},
   "source": [
    "## Step 5: View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7daeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load JSON report\n",
    "output_dir = Path(\"../outputs\")\n",
    "json_files = list(output_dir.glob(\"*_report.json\"))\n",
    "\n",
    "if json_files:\n",
    "    with open(json_files[0], 'r') as f:\n",
    "        report = json.load(f)\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(\"INFERENCE SUMMARY\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Total frames: {report['summary']['total_frames']}\")\n",
    "    print(f\"Total detections: {report['summary']['total_detections']}\")\n",
    "    print(f\"Unique objects: {report['summary']['unique_objects']}\")\n",
    "    print(f\"Avg detections/frame: {report['summary']['avg_detections_per_frame']:.2f}\")\n",
    "    print(\"=\" * 50)\n",
    "else:\n",
    "    print(\"No report found. Run demo inference first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff534c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first frame with detections\n",
    "first_frames = list(output_dir.glob(\"*_first_frame.jpg\"))\n",
    "\n",
    "if first_frames:\n",
    "    first_frame = cv2.imread(str(first_frames[0]))\n",
    "    first_frame = cv2.cvtColor(first_frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    plt.figure(figsize=(14, 10))\n",
    "    plt.imshow(first_frame)\n",
    "    plt.title(\"First Frame with Detections\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No first frame image found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5bc47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display CSV summary\n",
    "csv_files = list(output_dir.glob(\"*_summary.csv\"))\n",
    "\n",
    "if csv_files:\n",
    "    df = pd.read_csv(csv_files[0])\n",
    "    \n",
    "    print(\"\\nSummary DataFrame (first 10 rows):\")\n",
    "    print(df.head(10))\n",
    "    \n",
    "    # Plot detections over time\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.plot(df['frame_idx'], df['num_detections'], linewidth=2)\n",
    "    plt.xlabel('Frame Index')\n",
    "    plt.ylabel('Number of Detections')\n",
    "    plt.title('Detections Over Time')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No CSV summary found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4faaad7",
   "metadata": {},
   "source": [
    "## Step 6: Display Output Video\n",
    "\n",
    "View the annotated output video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27f66c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find output video\n",
    "output_videos = list(output_dir.glob(\"*_out.mp4\"))\n",
    "\n",
    "if output_videos:\n",
    "    print(f\"Output video: {output_videos[0].name}\")\n",
    "    print(\"\\nNote: Video playback may not work in all environments.\")\n",
    "    print(f\"View the video directly at: {output_videos[0]}\")\n",
    "    \n",
    "    # Try to display (may not work in all environments)\n",
    "    try:\n",
    "        Video(str(output_videos[0]), embed=True, width=800)\n",
    "    except:\n",
    "        print(\"Could not embed video. Open it manually.\")\n",
    "else:\n",
    "    print(\"No output video found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b8dd17",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Full Training**: Train with more epochs for better performance\n",
    "   ```bash\n",
    "   python src/train_yolo.py --epochs 50 --batch 16\n",
    "   ```\n",
    "\n",
    "2. **Auto Fine-tuning**: Improve model with pseudo-labeling\n",
    "   ```bash\n",
    "   python src/auto_finetune.py --weights runs/detect/video_merged/weights/best.pt --unlabeled datasets/samples/\n",
    "   ```\n",
    "\n",
    "3. **Process Full Dataset**: Remove `--dry-run` flag\n",
    "   ```bash\n",
    "   python src/data_pipeline.py\n",
    "   ```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
